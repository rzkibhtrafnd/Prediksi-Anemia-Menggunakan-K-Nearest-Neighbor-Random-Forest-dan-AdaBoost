# -*- coding: utf-8 -*-
"""Prediksi Diabetes Menggunakan K-Nearest Neighbor, Random Forest, dan AdaBoost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_6eOMcYvjsmbqNpC6AC0Likxaqjnd-DI

# **Import Library**
"""

import gdown
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

"""# **Data Loading**"""

url = 'https://drive.google.com/uc?id=1UcIf37Wi-ebSDr_ZMmRfxBE2ENflblV8'
output = 'diabetes.csv'

gdown.download(url, output, quiet=False)

df = pd.read_csv(output)

df.head()

"""# **Exploratory Data Analysis**"""

df.info()

df.describe()

# Visualisasi distribusi fitur numerik
numeric_columns = ['%Red Pixel', '%Green pixel', '%Blue pixel', 'Hb']
for col in numeric_columns:
    plt.figure(figsize=(6, 4))
    sns.histplot(df[col], kde=True, bins=30)
    plt.title(f'Distribution of {col}')
    plt.show()

# Heatmap untuk melihat korelasi antar fitur numerik
plt.figure(figsize=(8, 6))
sns.heatmap(df[numeric_columns].corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
plt.show()

# Distribusi fitur kategorikal
sns.countplot(x='Sex', data=df)
plt.title('Distribution of Sex')
plt.show()

sns.countplot(x='Anaemic', data=df)
plt.title('Distribution of Anaemic')
plt.show()

"""# **Data Preparation**"""

# Encoding fitur kategorikal
label_encoder = LabelEncoder()
df['Sex'] = label_encoder.fit_transform(df['Sex'])
df['Anaemic'] = label_encoder.fit_transform(df['Anaemic'])

# Feature scaling
scaler = StandardScaler()
df[numeric_columns] = scaler.fit_transform(df[numeric_columns])

# Membagi dataset menjadi data training dan testing
X = df[['Sex', '%Red Pixel', '%Green pixel', '%Blue pixel', 'Hb']]
y = df['Anaemic']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""# **Model Development**"""

# Model K-Nearest Neighbor
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)
y_pred_knn = knn_model.predict(X_test)

# Model Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

# Model Boosting Algorithm (AdaBoost)
ada_model = AdaBoostClassifier(n_estimators=50, random_state=42)
ada_model.fit(X_train, y_train)
y_pred_ada = ada_model.predict(X_test)

"""# **Evaluasi Model**"""

# Fungsi untuk mengevaluasi model
def evaluate_model(y_test, y_pred, model_name):
    print(f"Evaluation Metrics for {model_name}:")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Precision:", precision_score(y_test, y_pred))
    print("Recall:", recall_score(y_test, y_pred))
    print("F1 Score:", f1_score(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("Classification Report:\n", classification_report(y_test, y_pred))
    print("-" * 50)

    # Kembalikan metrik untuk digunakan dalam pemilihan model terbaik
    return {
        "Model": model_name,
        "Accuracy": accuracy_score(y_test, y_pred),
        "Precision": precision_score(y_test, y_pred),
        "Recall": recall_score(y_test, y_pred),
        "F1 Score": f1_score(y_test, y_pred)
    }

# Evaluasi semua model
results = []
results.append(evaluate_model(y_test, y_pred_knn, "K-Nearest Neighbor"))
results.append(evaluate_model(y_test, y_pred_rf, "Random Forest"))
results.append(evaluate_model(y_test, y_pred_ada, "AdaBoost"))

# Memilih model terbaik berdasarkan F1 Score
best_model_metrics = max(results, key=lambda x: x['F1 Score'])
best_model_name = best_model_metrics["Model"]

# Tampilkan model terbaik
print("\nModel terbaik berdasarkan F1 Score:")
print(best_model_metrics)

# Visualisasi Confusion Matrix untuk model terbaik
if best_model_name == "K-Nearest Neighbor":
    best_pred = y_pred_knn
elif best_model_name == "Random Forest":
    best_pred = y_pred_rf
else:
    best_pred = y_pred_ada

conf_matrix = confusion_matrix(y_test, best_pred)
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])
plt.title(f"Confusion Matrix of Best Model: {best_model_name}")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""# **Testing Model**"""

# Tampilkan hasil prediksi dalam tabel
def display_prediction_results_simple(results_df):
    print("\nSample Testing Results:")
    print(results_df.to_string(index=False))

display_prediction_results_simple(results_df)

"""# **Save Model**"""

import joblib

# Simpan model ke dalam file .pkl
joblib.dump(best_pred, 'best_model.pkl')
print("Model terbaik disimpan ke 'best_model.pkl'")